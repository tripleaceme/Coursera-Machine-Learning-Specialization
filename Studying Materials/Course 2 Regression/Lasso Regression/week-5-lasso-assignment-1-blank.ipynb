{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Week 5: Feature Selection and LASSO (Interpretation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will use LASSO to select features, building on a pre-implemented solver for LASSO (using GraphLab Create, though you can use other solvers). You will:\n",
    "* Run LASSO with different L1 penalties.\n",
    "* Choose best L1 penalty using a validation set.\n",
    "* Choose best L1 penalty using a validation set, with additional constraint on the size of subset.\n",
    "\n",
    "In the second notebook, you will implement your own LASSO solver, using coordinate descent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fire up Graphlab Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import graphlab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in house sales data\n",
    "\n",
    "Dataset is from house sales in King County, the region where the city of Seattle, WA is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.1 started. Logging: C:\\Users\\WILLKO~1\\AppData\\Local\\Temp\\graphlab_server_1503445344.log.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to wjk68@case.edu and will expire on August 11, 2018.\n"
     ]
    }
   ],
   "source": [
    "sales = graphlab.SFrame('kc_house_data.gl/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in Week 2, we consider features that are some transformations of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log, sqrt\n",
    "sales['sqft_living_sqrt'] = sales['sqft_living'].apply(sqrt)\n",
    "sales['sqft_lot_sqrt'] = sales['sqft_lot'].apply(sqrt)\n",
    "sales['bedrooms_square'] = sales['bedrooms']*sales['bedrooms']\n",
    "\n",
    "# In the dataset, 'floors' was defined with type string, \n",
    "# so we'll convert them to float, before creating a new feature.\n",
    "sales['floors'] = sales['floors'].astype(float) \n",
    "sales['floors_square'] = sales['floors']*sales['floors']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Squaring bedrooms will increase the separation between not many bedrooms (e.g. 1) and lots of bedrooms (e.g. 4) since 1^2 = 1 but 4^2 = 16. Consequently this variable will mostly affect houses with many bedrooms.\n",
    "* On the other hand, taking square root of sqft_living will decrease the separation between big house and small house. The owner may not be exactly twice as happy for getting a house that is twice as big."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn regression weights with L1 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us fit a model with all the features available, plus the features we just created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_features = ['bedrooms', 'bedrooms_square',\n",
    "            'bathrooms',\n",
    "            'sqft_living', 'sqft_living_sqrt',\n",
    "            'sqft_lot', 'sqft_lot_sqrt',\n",
    "            'floors', 'floors_square',\n",
    "            'waterfront', 'view', 'condition', 'grade',\n",
    "            'sqft_above',\n",
    "            'sqft_basement',\n",
    "            'yr_built', 'yr_renovated']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying L1 penalty requires adding an extra parameter (`l1_penalty`) to the linear regression call in GraphLab Create. (Other tools may have separate implementations of LASSO.)  Note that it's important to set `l2_penalty=0` to ensure we don't introduce an additional L2 penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Linear regression:</pre>"
      ],
      "text/plain": [
       "Linear regression:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 21613</pre>"
      ],
      "text/plain": [
       "Number of examples          : 21613"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of features          : 17</pre>"
      ],
      "text/plain": [
       "Number of features          : 17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 17</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of coefficients    : 18</pre>"
      ],
      "text/plain": [
       "Number of coefficients    : 18"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Starting Accelerated Gradient (FISTA)</pre>"
      ],
      "text/plain": [
       "Starting Accelerated Gradient (FISTA)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+--------------------+---------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+--------------------+---------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Passes   | Step size | Elapsed Time | Training-max_error | Training-rmse |</pre>"
      ],
      "text/plain": [
       "| Iteration | Passes   | Step size | Elapsed Time | Training-max_error | Training-rmse |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+--------------------+---------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+--------------------+---------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Tuning step size. First iteration could take longer than subsequent iterations.</pre>"
      ],
      "text/plain": [
       "Tuning step size. First iteration could take longer than subsequent iterations."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 2        | 0.000002  | 1.397403     | 6962915.603493     | 426631.749026 |</pre>"
      ],
      "text/plain": [
       "| 1         | 2        | 0.000002  | 1.397403     | 6962915.603493     | 426631.749026 |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 3        | 0.000002  | 1.428487     | 6843144.200219     | 392488.929838 |</pre>"
      ],
      "text/plain": [
       "| 2         | 3        | 0.000002  | 1.428487     | 6843144.200219     | 392488.929838 |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 4        | 0.000002  | 1.475626     | 6831900.032123     | 385340.166783 |</pre>"
      ],
      "text/plain": [
       "| 3         | 4        | 0.000002  | 1.475626     | 6831900.032123     | 385340.166783 |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 5        | 0.000002  | 1.538793     | 6847166.848958     | 384842.383767 |</pre>"
      ],
      "text/plain": [
       "| 4         | 5        | 0.000002  | 1.538793     | 6847166.848958     | 384842.383767 |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 5         | 6        | 0.000002  | 1.592946     | 6869667.895833     | 385998.458623 |</pre>"
      ],
      "text/plain": [
       "| 5         | 6        | 0.000002  | 1.592946     | 6869667.895833     | 385998.458623 |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 6         | 7        | 0.000002  | 1.650098     | 6847177.773672     | 380824.455891 |</pre>"
      ],
      "text/plain": [
       "| 6         | 7        | 0.000002  | 1.650098     | 6847177.773672     | 380824.455891 |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+----------+-----------+--------------+--------------------+---------------+</pre>"
      ],
      "text/plain": [
       "+-----------+----------+-----------+--------------+--------------------+---------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>TERMINATED: Iteration limit reached.</pre>"
      ],
      "text/plain": [
       "TERMINATED: Iteration limit reached."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>This model may not be optimal. To improve it, consider increasing `max_iterations`.</pre>"
      ],
      "text/plain": [
       "This model may not be optimal. To improve it, consider increasing `max_iterations`."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_all = graphlab.linear_regression.create(sales, target='price', features=all_features,\n",
    "                                              validation_set=None, \n",
    "                                              l2_penalty=0., l1_penalty=1e10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find what features had non-zero weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "non_zero_model_all = model_all.coefficients[model_all.coefficients['value'] > 0.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that a majority of the weights have been set to zero. So by setting an L1 penalty that's large enough, we are performing a subset selection. \n",
    "\n",
    "***QUIZ QUESTION***:\n",
    "According to this list of weights, which of the features have been chosen? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(intercept)', 'bathrooms', 'sqft_living', 'sqft_living_sqrt', 'grade', 'sqft_above']\n"
     ]
    }
   ],
   "source": [
    "print(non_zero_model_all['name'][:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting an L1 penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find a good L1 penalty, we will explore multiple values using a validation set. Let us do three way split into train, validation, and test sets:\n",
    "* Split our sales data into 2 sets: training and test\n",
    "* Further split our training data into two sets: train, validation\n",
    "\n",
    "Be *very* careful that you use seed = 1 to ensure you get the same answer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(training_and_validation, testing) = sales.random_split(.9,seed=1) # initial train/test split\n",
    "(training, validation) = training_and_validation.random_split(0.5, seed=1) # split training into train and validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we write a loop that does the following:\n",
    "* For `l1_penalty` in [10^1, 10^1.5, 10^2, 10^2.5, ..., 10^7] (to get this in Python, type `np.logspace(1, 7, num=13)`.)\n",
    "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty` and `l2_penalty=0.` in the parameter list.\n",
    "    * Compute the RSS on VALIDATION data (here you will want to use `.predict()`) for that `l1_penalty`\n",
    "* Report which `l1_penalty` produced the lowest RSS on validation data.\n",
    "\n",
    "When you call `linear_regression.create()` make sure you set `validation_set = None`.\n",
    "\n",
    "Note: you can turn off the print out of `linear_regression.create()` with `verbose = False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bedrooms',\n",
       " 'bedrooms_square',\n",
       " 'bathrooms',\n",
       " 'sqft_living',\n",
       " 'sqft_living_sqrt',\n",
       " 'sqft_lot',\n",
       " 'sqft_lot_sqrt',\n",
       " 'floors',\n",
       " 'floors_square',\n",
       " 'waterfront',\n",
       " 'view',\n",
       " 'condition',\n",
       " 'grade',\n",
       " 'sqft_above',\n",
       " 'sqft_basement',\n",
       " 'yr_built',\n",
       " 'yr_renovated']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "l1_penalties = np.logspace(1, 7, num=13)\n",
    "validation_scores = []\n",
    "\n",
    "for penalty in l1_penalties:\n",
    "    model = graphlab.linear_regression.create(training, target='price', features=all_features, \n",
    "                                             l2_penalty=0.0, l1_penalty=penalty, validation_set=None, verbose=False)\n",
    "    predictions = model.predict(validation)\n",
    "    RSS = ( (predictions-validation['price'])**2).sum()\n",
    "    validation_scores.append((penalty, RSS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_scores = sorted(validation_scores, key=lambda x: x[1], reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10.0, 625766285142459.9),\n",
       " (31.622776601683793, 625766285362394.1),\n",
       " (100.0, 625766286057885.0),\n",
       " (316.2277660168379, 625766288257224.6),\n",
       " (1000.0, 625766295212186.8),\n",
       " (3162.2776601683795, 625766317206080.5),\n",
       " (10000.0, 625766386760658.1),\n",
       " (31622.776601683792, 625766606749278.5),\n",
       " (100000.0, 625767302791634.1),\n",
       " (316227.76601683791, 625769507643886.2),\n",
       " (1000000.0, 625776517727024.0),\n",
       " (3162277.6601683791, 625799062845467.0),\n",
       " (10000000.0, 625883719085425.2)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** QUIZ QUESTION. *** What was the best value for the `l1_penalty`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best validation RSS of 6.25766285142e+14 occured with an L1 penalty of 10.0\n"
     ]
    }
   ],
   "source": [
    "print('The best validation RSS of {} occured with an L1 penalty of {}'.format(validation_scores[0][1], validation_scores[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTION***\n",
    "Also, using this value of L1 penalty, how many nonzero weights do you have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_best_penalty = graphlab.linear_regression.create(training, target='price', features=all_features, \n",
    "                                                         l2_penalty=0.0, l1_penalty=10.0, validation_set=None, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_best_penalty['coefficients']['value'].nnz()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limit the number of nonzero weights\n",
    "\n",
    "What if we absolutely wanted to limit ourselves to, say, 7 features? This may be important if we want to derive \"a rule of thumb\" --- an interpretable model that has only a few features in them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you are going to implement a simple, two phase procedure to achive this goal:\n",
    "1. Explore a large range of `l1_penalty` values to find a narrow region of `l1_penalty` values where models are likely to have the desired number of non-zero weights.\n",
    "2. Further explore the narrow region you found to find a good value for `l1_penalty` that achieves the desired sparsity.  Here, we will again use a validation set to choose the best value for `l1_penalty`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_nonzeros = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the larger range of values to find a narrow range with the desired sparsity\n",
    "\n",
    "Let's define a wide range of possible `l1_penalty_values`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l1_penalty_values = np.logspace(8, 10, num=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, implement a loop that search through this space of possible `l1_penalty` values:\n",
    "\n",
    "* For `l1_penalty` in `np.logspace(8, 10, num=20)`:\n",
    "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty` and `l2_penalty=0.` in the parameter list. When you call `linear_regression.create()` make sure you set `validation_set = None`\n",
    "    * Extract the weights of the model and count the number of nonzeros. Save the number of nonzeros to a list.\n",
    "        * *Hint: `model['coefficients']['value']` gives you an SArray with the parameters you learned.  If you call the method `.nnz()` on it, you will find the number of non-zero parameters!* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1_penalties = np.logspace(8, 10, num=20)\n",
    "non_zeros = []\n",
    "\n",
    "for penalty in l1_penalties:\n",
    "    model = graphlab.linear_regression.create(training, target='price', features=all_features,\n",
    "                                              l2_penalty=0.0, l1_penalty=penalty, validation_set=None,\n",
    "                                              verbose=False)\n",
    "    non_zeros.append((penalty, model['coefficients']['value'].nnz()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ab479b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l1_values = [data[0] for data in non_zeros]\n",
    "non_zero_values = [data[1] for data in non_zeros]\n",
    "\n",
    "plt.plot(l1_values, non_zero_values, \".\")\n",
    "plt.ylabel('non-zero values'); plt.xlabel('l1 regularization parameter');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of this large range, we want to find the two ends of our desired narrow range of `l1_penalty`.  At one end, we will have `l1_penalty` values that have too few non-zeros, and at the other end, we will have an `l1_penalty` that has too many non-zeros.  \n",
    "\n",
    "More formally, find:\n",
    "* The largest `l1_penalty` that has more non-zeros than `max_nonzeros` (if we pick a penalty smaller than this value, we will definitely have too many non-zero weights)\n",
    "    * Store this value in the variable `l1_penalty_min` (we will use it later)\n",
    "* The smallest `l1_penalty` that has fewer non-zeros than `max_nonzeros` (if we pick a penalty larger than this value, we will definitely have too few non-zero weights)\n",
    "    * Store this value in the variable `l1_penalty_max` (we will use it later)\n",
    "\n",
    "\n",
    "*Hint: there are many ways to do this, e.g.:*\n",
    "* Programmatically within the loop above\n",
    "* Creating a list with the number of non-zeros for each value of `l1_penalty` and inspecting it to find the appropriate boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "more_non_zeros = (filter(lambda x: x[1]>7, non_zeros))\n",
    "fewer_non_zeros = (filter(lambda x: x[1]<7, non_zeros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2976351441.6313128"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([data[0] for data in more_non_zeros])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3792690190.7322536"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min([data[0] for data in fewer_non_zeros])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l1_penalty_min = max([data[0] for data in more_non_zeros])\n",
    "l1_penalty_max = min([data[0] for data in fewer_non_zeros])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2742749857031375"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_penalty_max / l1_penalty_min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTION.*** What values did you find for `l1_penalty_min` and `l1_penalty_max`, respectively? \n",
    "\n",
    "2976351441.6313128\n",
    "\n",
    "3792690190.7322536"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the narrow range of values to find the solution with the right number of non-zeros that has lowest RSS on the validation set \n",
    "\n",
    "We will now explore the narrow region of `l1_penalty` values we found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1_penalty_values = np.linspace(l1_penalty_min,l1_penalty_max,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For `l1_penalty` in `np.linspace(l1_penalty_min,l1_penalty_max,20)`:\n",
    "    * Fit a regression model with a given `l1_penalty` on TRAIN data. Specify `l1_penalty=l1_penalty` and `l2_penalty=0.` in the parameter list. When you call `linear_regression.create()` make sure you set `validation_set = None`\n",
    "    * Measure the RSS of the learned model on the VALIDATION set\n",
    "\n",
    "Find the model that the lowest RSS on the VALIDATION set and has sparsity *equal* to `max_nonzeros`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_scores = []\n",
    "\n",
    "for penalty in l1_penalty_values:\n",
    "    model = graphlab.linear_regression.create(training, target='price', features=all_features,\n",
    "                                              l2_penalty=0.0, l1_penalty=penalty, \n",
    "                                              validation_set=None, verbose=False)\n",
    "    if model['coefficients']['value'].nnz() == max_nonzeros:\n",
    "        predictions = model.predict(validation)\n",
    "        RSS = ( (predictions-validation['price'])**2).sum()\n",
    "        validation_scores.append((penalty, RSS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_scores = sorted(validation_scores, key=lambda x: x[1], reverse=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTIONS***\n",
    "1. What value of `l1_penalty` in our narrow range has the lowest RSS on the VALIDATION set and has sparsity *equal* to `max_nonzeros`?\n",
    "2. What features in this model have non-zero coefficients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The l1_penalty with sparsity equal to max_nonzeros(7) is 3448968612.16\n",
      "The RSS for this model is 1.04693748875e+15\n"
     ]
    }
   ],
   "source": [
    "ideal_l1_penalty = validation_scores[0][0]\n",
    "print('The l1_penalty with sparsity equal to max_nonzeros(7) is {}'.format(ideal_l1_penalty))\n",
    "print('The RSS for this model is {}'.format(str(validation_scores[0][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model = graphlab.linear_regression.create(training, target='price', features=all_features,\n",
    "                                                l2_penalty=0.0, l1_penalty=ideal_l1_penalty, \n",
    "                                                validation_set=None, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(intercept)',\n",
       " 'bedrooms',\n",
       " 'bathrooms',\n",
       " 'sqft_living',\n",
       " 'sqft_living_sqrt',\n",
       " 'grade',\n",
       " 'sqft_above']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(final_model['coefficients'][final_model['coefficients']['value'] > 0.0]['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
